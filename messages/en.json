{
  "common": {
    "save": "Save",
    "cancel": "Cancel",
    "delete": "Delete",
    "edit": "Edit",
    "create": "Create",
    "search": "Search",
    "loading": "Loading...",
    "error": "Something went wrong",
    "retry": "Retry",
    "confirm": "Confirm",
    "close": "Close",
    "back": "Back",
    "next": "Next",
    "skip": "Skip",
    "finish": "Finish",
    "export": "Export",
    "refresh": "Refresh",
    "noResults": "No results found",
    "appName": "Ollama Admin"
  },
  "sidebar": {
    "dashboard": "Dashboard",
    "chat": "Chat",
    "discover": "Discover",
    "models": "Models",
    "servers": "Servers",
    "logs": "Logs",
    "metrics": "Metrics",
    "gpu": "GPU",
    "settings": "Settings"
  },
  "dashboard": {
    "title": "Dashboard",
    "servers": "Servers",
    "models": "Models",
    "recentActivity": "Recent Activity",
    "activeModels": "Active Models",
    "quickActions": "Quick Actions",
    "newChat": "New Chat",
    "pullModel": "Pull Model",
    "addServer": "Add Server",
    "emptyTitle": "Welcome to Ollama Admin",
    "emptyDescription": "Add your first Ollama server to get started.",
    "emptyAction": "Add Server"
  },
  "chat": {
    "title": "Chat",
    "newConversation": "New Conversation",
    "sendMessage": "Send message",
    "stopGeneration": "Stop generation",
    "selectModel": "Select a model",
    "selectServer": "Select a server",
    "typeMessage": "Type a message...",
    "searchConversations": "Search conversations...",
    "emptyTitle": "No conversations yet",
    "emptyDescription": "Start your first conversation with an AI model.",
    "emptyAction": "New Conversation",
    "tokens": "tokens",
    "latency": "latency",
    "editMessage": "Edit message",
    "editSend": "Save & resend",
    "editCancel": "Cancel",
    "regenerate": "Regenerate response",
    "exportMarkdown": "Export as Markdown",
    "exportJson": "Export as JSON",
    "attachImage": "Attach image",
    "parameters": {
      "title": "Parameters",
      "temperature": "Temperature",
      "topK": "Top K",
      "topP": "Top P",
      "repeatPenalty": "Repeat Penalty",
      "seed": "Seed",
      "numCtx": "Context Length",
      "numPredict": "Max Tokens",
      "stop": "Stop Sequences",
      "stopPlaceholder": "Comma-separated",
      "keepAlive": "Keep Alive",
      "systemPrompt": "System Prompt",
      "systemPromptPlaceholder": "Custom instructions for the model...",
      "reset": "Reset"
    },
    "presets": {
      "save": "Save preset",
      "saved": "Preset saved",
      "saveError": "Error saving preset",
      "loaded": "Preset \"{name}\" applied",
      "deleted": "Preset deleted",
      "deleteError": "Error deleting preset",
      "deletePreset": "Delete preset {name}",
      "namePlaceholder": "Preset name..."
    }
  },
  "discover": {
    "title": "Discover Models",
    "searchModels": "Search models...",
    "filterByFamily": "Filter by family",
    "allFamilies": "All families",
    "maxVram": "Max VRAM",
    "pullModel": "Pull",
    "installed": "Installed",
    "downloads": "downloads",
    "lastUpdated": "Last updated",
    "refreshCatalog": "Refresh Catalog",
    "lastRefresh": "Last refresh",
    "emptyTitle": "Catalog is empty",
    "emptyDescription": "Refresh the catalog to browse available models.",
    "emptyAction": "Refresh Catalog"
  },
  "admin": {
    "models": {
      "title": "Models",
      "pullModel": "Pull Model",
      "pullPlaceholder": "e.g. llama3.1:8b",
      "deleteConfirm": "Are you sure you want to delete {model}? This cannot be undone.",
      "inspect": "Inspect",
      "copy": "Copy",
      "copyDestination": "Destination name",
      "emptyTitle": "No models installed",
      "emptyDescription": "Browse the catalog to find and download models.",
      "emptyAction": "Browse Catalog",
      "name": "Name",
      "size": "Size",
      "family": "Family",
      "quantization": "Quantization",
      "modified": "Modified"
    },
    "servers": {
      "title": "Servers",
      "addServer": "Add Server",
      "editServer": "Edit Server",
      "testConnection": "Test Connection",
      "serverName": "Server name",
      "serverUrl": "Server URL",
      "gpuAgentUrl": "GPU Agent URL (optional)",
      "active": "Active",
      "online": "Online",
      "offline": "Offline",
      "deleteConfirm": "Are you sure you want to delete this server?",
      "emptyTitle": "No servers configured",
      "emptyDescription": "Add your first Ollama server to get started.",
      "emptyAction": "Add Server"
    },
    "logs": {
      "title": "Logs",
      "filterByServer": "Filter by server",
      "filterByModel": "Filter by model",
      "filterByStatus": "Filter by status",
      "dateRange": "Date range",
      "exportCsv": "Export CSV",
      "exportJson": "Export JSON",
      "emptyTitle": "No logs yet",
      "emptyDescription": "Logs will appear here as you use the chat or API.",
      "timestamp": "Timestamp",
      "server": "Server",
      "model": "Model",
      "endpoint": "Endpoint",
      "promptTokens": "Prompt tokens",
      "completionTokens": "Completion tokens",
      "totalTokens": "Total tokens",
      "latency": "Latency",
      "status": "Status"
    },
    "metrics": {
      "title": "Metrics",
      "dateRange": "Time range",
      "last7days": "Last 7 days",
      "last30days": "Last 30 days",
      "last90days": "Last 90 days",
      "totalRequests": "Total Requests",
      "topModel": "Top Model",
      "avgLatency": "Avg Latency",
      "errorRate": "Error Rate",
      "requestsOverTime": "Requests Over Time",
      "tokensByModel": "Tokens by Model",
      "avgLatencyByModel": "Avg Latency by Model",
      "mostUsedModels": "Most Used Models",
      "emptyTitle": "No metrics yet",
      "emptyDescription": "Metrics will appear as requests flow through the gateway."
    },
    "gpu": {
      "title": "GPU Monitoring",
      "refresh": "Refresh",
      "offline": "Offline",
      "runningModels": "Running Models",
      "noModelsLoaded": "No models loaded",
      "noModelsLoadedDescription": "Models will appear here when loaded into memory by Ollama.",
      "totalSize": "Total",
      "expiresAt": "Expires",
      "gpuHardware": "GPU Hardware",
      "vramUsage": "VRAM Usage",
      "utilization": "GPU Utilization",
      "emptyTitle": "No servers configured",
      "emptyDescription": "Add an Ollama server to monitor GPU usage."
    }
  },
  "setup": {
    "title": "Welcome to Ollama Admin",
    "step1Title": "Connect to Ollama",
    "step1Description": "Let's find your Ollama server.",
    "detecting": "Detecting Ollama...",
    "connected": "Connected to Ollama",
    "connectionFailed": "Could not connect to Ollama",
    "tryCustomUrl": "Try a different URL",
    "testConnection": "Test Connection",
    "step2Title": "Download a Model",
    "step2Description": "Choose a model to get started.",
    "step2Skip": "Skip — I'll do this later",
    "downloading": "Downloading...",
    "downloadComplete": "Download complete!",
    "step3Title": "Optional Settings",
    "step3Description": "Customize your experience. You can change these later.",
    "serverName": "Server name",
    "theme": "Theme",
    "themeLight": "Light",
    "themeDark": "Dark",
    "themeAuto": "Auto",
    "next": "Next",
    "back": "Back",
    "finish": "Finish"
  },
  "settings": {
    "title": "Settings",
    "appearance": "Appearance",
    "theme": "Theme",
    "themeLight": "Light",
    "themeDark": "Dark",
    "themeAuto": "Auto",
    "density": "UI Density",
    "compact": "Compact",
    "normal": "Normal",
    "spacious": "Spacious",
    "language": "Language",
    "loggingPrivacy": "Logging & Privacy",
    "logRetentionDays": "Log retention (days)",
    "storePrompts": "Store prompt content",
    "storePromptsYes": "Yes — store full prompts and responses",
    "storePromptsNo": "No — store only metadata (tokens, latency)",
    "saveChanges": "Save Changes",
    "saved": "Settings saved",
    "purgeLogs": "Purge Old Logs",
    "logsPurged": "Old logs deleted",
    "database": "Database",
    "connected": "Connected",
    "databaseType": "SQLite (default)"
  }
}
